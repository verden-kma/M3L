import numpy as np
import matplotlib.pyplot as plt

passed_predicted_probabilities = np.array(
    [0.870241125905335, 0.7442454916767064, 0.22844196304701853, 0.870241125905335, 0.870241125905335,
     0.10899913013637949, 0.22844196304701853, 0.10899913013637949, 0.40559875579354854, 0.10899913013637949,
     0.870241125905335, 0.5459393515768596, 0.10899913013637949, 0.22844196304701853, 0.10899913013637949,
     0.22844196304701853, 0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.10899913013637949,
     0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.7442454916767064, 0.7768307820642292,
     0.5459393515768596, 0.7442454916767064, 0.7768307820642292, 0.870241125905335, 0.5459393515768596,
     0.22844196304701853, 0.7442454916767064, 0.7442454916767064, 0.870241125905335, 0.10899913013637949,
     0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.7442454916767064, 0.8938958421947213,
     0.40559875579354854, 0.10899913013637949, 0.7442454916767064, 0.10899913013637949, 0.7442454916767064,
     0.22844196304701853, 0.40559875579354854, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949,
     0.2615379368660234, 0.7442454916767064, 0.5459393515768596, 0.10899913013637949, 0.870241125905335,
     0.4615474307295475, 0.10899913013637949, 0.5459393515768596, 0.870241125905335, 0.8938958421947213,
     0.7768307820642292, 0.870241125905335, 0.870241125905335, 0.10899913013637949, 0.870241125905335,
     0.10899913013637949, 0.10899913013637949, 0.2615379368660234, 0.10899913013637949, 0.7442454916767064,
     0.22844196304701853, 0.7768307820642292, 0.7442454916767064, 0.22844196304701853, 0.40559875579354854,
     0.10899913013637949, 0.870241125905335, 0.870241125905335, 0.40559875579354854, 0.10899913013637949,
     0.5459393515768596, 0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.10899913013637949,
     0.10899913013637949, 0.870241125905335, 0.22844196304701853, 0.10899913013637949, 0.22844196304701853,
     0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.5459393515768596, 0.5459393515768596,
     0.10899913013637949, 0.10899913013637949, 0.7442454916767064, 0.5459393515768596, 0.5459393515768596,
     0.10899913013637949, 0.10899913013637949, 0.10899913013637949, 0.22844196304701853, 0.10899913013637949,
     0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.40559875579354854, 0.10899913013637949,
     0.10899913013637949, 0.2615379368660234, 0.40559875579354854, 0.7442454916767064, 0.22844196304701853,
     0.870241125905335, 0.10899913013637949, 0.10899913013637949, 0.5459393515768596, 0.10899913013637949,
     0.40559875579354854, 0.22844196304701853, 0.5459393515768596, 0.10899913013637949, 0.870241125905335,
     0.10899913013637949, 0.870241125905335, 0.5459393515768596, 0.5459393515768596, 0.10899913013637949,
     0.5459393515768596, 0.22844196304701853, 0.5459393515768596, 0.870241125905335, 0.10899913013637949,
     0.22844196304701853, 0.4615474307295475, 0.8938958421947213, 0.7442454916767064, 0.22844196304701853,
     0.10899913013637949, 0.10899913013637949, 0.5459393515768596, 0.870241125905335, 0.870241125905335,
     0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.7768307820642292, 0.7442454916767064, 0.10899913013637949, 0.7442454916767064,
     0.40559875579354854, 0.22844196304701853, 0.10899913013637949, 0.5459393515768596, 0.5459393515768596,
     0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.40559875579354854, 0.7442454916767064, 0.870241125905335, 0.5459393515768596,
     0.40559875579354854, 0.22844196304701853, 0.870241125905335, 0.870241125905335, 0.870241125905335,
     0.40559875579354854, 0.10899913013637949, 0.870241125905335, 0.10899913013637949, 0.10899913013637949,
     0.22844196304701853, 0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.22844196304701853,
     0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.40559875579354854, 0.22844196304701853,
     0.7768307820642292, 0.22844196304701853, 0.10899913013637949, 0.5459393515768596, 0.22844196304701853,
     0.7768307820642292, 0.870241125905335, 0.10899913013637949, 0.22844196304701853, 0.870241125905335,
     0.10899913013637949, 0.40559875579354854, 0.5459393515768596, 0.870241125905335, 0.10899913013637949,
     0.10899913013637949, 0.10899913013637949, 0.2615379368660234, 0.5459393515768596, 0.10899913013637949,
     0.870241125905335, 0.10899913013637949, 0.870241125905335, 0.10899913013637949, 0.5459393515768596,
     0.22844196304701853, 0.40559875579354854, 0.5459393515768596, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.22844196304701853, 0.5459393515768596, 0.7442454916767064, 0.10899913013637949,
     0.40559875579354854, 0.870241125905335, 0.10899913013637949, 0.7442454916767064, 0.22844196304701853,
     0.40559875579354854, 0.22844196304701853, 0.22844196304701853, 0.870241125905335, 0.40559875579354854,
     0.10899913013637949, 0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.2615379368660234,
     0.10899913013637949, 0.22844196304701853, 0.7442454916767064, 0.22844196304701853, 0.10899913013637949,
     0.22844196304701853, 0.7442454916767064, 0.10899913013637949, 0.22844196304701853, 0.2615379368660234,
     0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949,
     0.40559875579354854, 0.10899913013637949, 0.22844196304701853, 0.870241125905335, 0.870241125905335,
     0.40559875579354854, 0.10899913013637949, 0.22844196304701853, 0.870241125905335, 0.870241125905335,
     0.10899913013637949, 0.870241125905335, 0.40559875579354854, 0.40559875579354854, 0.10899913013637949,
     0.10899913013637949, 0.2615379368660234, 0.10899913013637949, 0.10899913013637949, 0.10899913013637949,
     0.2615379368660234, 0.10899913013637949, 0.22844196304701853, 0.40559875579354854, 0.5459393515768596,
     0.7442454916767064, 0.7442454916767064, 0.7442454916767064, 0.7442454916767064, 0.40559875579354854,
     0.10899913013637949, 0.5459393515768596, 0.7442454916767064, 0.2615379368660234, 0.22844196304701853,
     0.10899913013637949, 0.10899913013637949, 0.10899913013637949, 0.40559875579354854, 0.22844196304701853,
     0.870241125905335, 0.22844196304701853, 0.10899913013637949, 0.40559875579354854, 0.22844196304701853,
     0.7442454916767064, 0.22844196304701853, 0.6639227853649052, 0.10899913013637949, 0.22844196304701853,
     0.22844196304701853, 0.22844196304701853, 0.10899913013637949, 0.22844196304701853, 0.870241125905335,
     0.22844196304701853, 0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.2615379368660234, 0.870241125905335, 0.870241125905335, 0.2615379368660234,
     0.7768307820642292, 0.870241125905335, 0.7442454916767064, 0.10899913013637949, 0.10899913013637949,
     0.10899913013637949, 0.10899913013637949, 0.40559875579354854, 0.10899913013637949, 0.2615379368660234,
     0.7442454916767064, 0.7442454916767064, 0.10899913013637949, 0.5459393515768596, 0.870241125905335,
     0.870241125905335, 0.10899913013637949, 0.2615379368660234, 0.7442454916767064, 0.870241125905335,
     0.22844196304701853, 0.22844196304701853, 0.40559875579354854, 0.10899913013637949, 0.2615379368660234,
     0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.22844196304701853, 0.22844196304701853,
     0.22844196304701853, 0.22844196304701853, 0.7442454916767064, 0.10899913013637949, 0.22844196304701853,
     0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.10899913013637949, 0.22844196304701853,
     0.10899913013637949, 0.870241125905335, 0.5459393515768596, 0.40559875579354854, 0.40559875579354854,
     0.5459393515768596, 0.10899913013637949, 0.40559875579354854, 0.7442454916767064, 0.870241125905335,
     0.5459393515768596, 0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.22844196304701853,
     0.22844196304701853, 0.40559875579354854, 0.22844196304701853, 0.870241125905335, 0.5459393515768596,
     0.10899913013637949, 0.40559875579354854, 0.10899913013637949, 0.10899913013637949, 0.2615379368660234,
     0.40559875579354854, 0.5459393515768596, 0.10899913013637949, 0.870241125905335, 0.10899913013637949,
     0.870241125905335, 0.6639227853649052, 0.22844196304701853, 0.22844196304701853, 0.2615379368660234,
     0.22844196304701853, 0.10899913013637949, 0.10899913013637949, 0.5459393515768596, 0.5459393515768596,
     0.10899913013637949, 0.10899913013637949, 0.5459393515768596, 0.10899913013637949, 0.5459393515768596,
     0.8938958421947213, 0.10899913013637949, 0.7442454916767064, 0.22844196304701853, 0.5459393515768596,
     0.10899913013637949, 0.6639227853649052, 0.22844196304701853, 0.5459393515768596, 0.10899913013637949,
     0.5459393515768596, 0.10899913013637949, 0.40559875579354854, 0.40559875579354854, 0.870241125905335,
     0.10899913013637949, 0.10899913013637949, 0.40559875579354854, 0.870241125905335, 0.5459393515768596,
     0.7442454916767064, 0.7442454916767064, 0.5459393515768596, 0.7768307820642292, 0.10899913013637949])

passed_true_labels = np.array(
    [True, True, False, True, True, False, False, False, False, False, True, False, False, False, False, False, False,
     True, False, True, False, False, True, True, False, False, False, True, True, False, False, True, True, True,
     False, True, False, False, False, True, False, False, True, False, True, False, True, False, True, False, False,
     True, True, False, True, True, False, False, True, True, False, True, True, False, True, False, False, False,
     False, True, False, True, True, False, False, True, True, True, False, False, True, False, True, True, True, False,
     True, False, False, False, True, True, False, False, True, False, False, True, True, False, False, False, True,
     False, False, True, False, False, True, False, False, False, False, True, False, True, False, True, False, False,
     False, False, True, False, True, False, False, True, True, False, True, False, False, True, False, False, True,
     True, False, False, True, False, False, True, True, False, False, False, False, False, False, False, False, False,
     True, False, False, False, False, True, False, False, False, False, False, False, True, True, True, True, True,
     False, True, True, True, False, False, True, False, False, False, False, False, True, False, False, True, False,
     False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, True, False,
     False, False, True, False, False, True, False, True, False, True, False, False, True, False, False, False, False,
     True, True, True, False, True, False, True, False, True, True, False, True, True, False, False, False, False,
     False, False, False, True, False, False, False, True, True, False, False, False, False, False, False, True, True,
     False, False, False, False, False, False, False, True, True, False, False, False, True, True, False, True, True,
     False, True, False, False, False, False, True, False, False, False, False, True, False, True, True, True, False,
     False, True, True, False, False, False, False, True, False, False, True, False, False, False, False, True, False,
     True, True, False, False, False, False, False, True, False, False, True, False, True, True, True, True, True,
     False, False, True, True, False, False, False, False, False, False, False, True, True, False, True, True, True,
     False, True, False, True, True, False, False, False, True, False, False, False, False, True, False, False, True,
     True, False, False, True, False, False, True, False, False, False, False, False, False, True, False, True, True,
     False, False, True, True, True, False, False, False, True, True, False, False, False, True, True, False, False,
     False, True, False, True, True, False, True, False, False, False, False, False, True, False, False, False, False,
     True, True, False, False, False, True, False, True, False, True, False, False, False, True, True, True, False,
     False, False, True, True, True, False, False, False, True])


def get_roc_numerics(predicted_probabilities: np.ndarray, true_labels: np.ndarray):
    thresholds = np.unique(predicted_probabilities)
    thresholds = np.append(np.append(np.array([0]), thresholds), 1)

    res_rates: list[tuple[float, float]] = []
    for threshold in thresholds:
        temp: list[bool] = []
        for predicted in predicted_probabilities:
            temp.append(predicted > threshold)
        zipped: list[tuple[bool, bool]] = list(zip(temp, true_labels))
        tp = len(list(filter(lambda x: x[0] == x[1] == True, zipped)))
        fp = len(list(filter(lambda x: x[0] == True and x[1] == False, zipped)))
        tn = len(list(filter(lambda x: x[0] == x[1] == False, zipped)))
        fn = len(list(filter(lambda x: x[0] == False and x[1] == True, zipped)))
        local_tpr = tp / (tp + fn)
        local_fpr = fp / (fp + tn)
        res_rates.append((local_tpr, local_fpr))
    return res_rates


def my_roc_function(predicted_probabilities: np.ndarray, true_labels: np.ndarray):
    roc_data = get_roc_numerics(predicted_probabilities, true_labels)
    tpr, fpr = zip(*roc_data)

    plt.plot(fpr, tpr, label="roc function")
    plt.legend(loc=4)
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.show()


my_roc_function(passed_predicted_probabilities, passed_true_labels)
